{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xc6TmC7HWpJa"
   },
   "source": [
    "# Load videos, synch frames with command velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "executionInfo": {
     "elapsed": 48859,
     "status": "error",
     "timestamp": 1733051400180,
     "user": {
      "displayName": "Anton Shoham",
      "userId": "18304469040041226183"
     },
     "user_tz": 480
    },
    "id": "ua3eBooARjDz",
    "outputId": "58405cd8-7cd5-4d3f-b194-ba0945bdc5ce"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os   \n",
    "# Define directories\n",
    "video_dir = r'C:\\Users\\anton\\Documents\\Competition Project\\Videos+timestamps'\n",
    "commands_dir = r'C:\\Users\\anton\\Documents\\Competition Project\\commands'\n",
    "\n",
    "# Get a list of all .mp4 video files and corresponding timestamp CSVs\n",
    "video_files = [f for f in os.listdir(video_dir) if f.endswith('.mp4')]\n",
    "timestamp_files = {f: os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.startswith('timestamps_') and f.endswith('.csv')}\n",
    "\n",
    "# Frame preprocessing parameters\n",
    "img_size = (112, 112)  # Resize dimensions\n",
    "max_sync_gap = 0.5  # Maximum time gap for velocity synchronization (in seconds)\n",
    "\n",
    "# Initialize a dictionary to store data for each video\n",
    "data = {}\n",
    "\n",
    "# Loop through each video\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_dir, video_file)\n",
    "    print(f\"Processing video: {video_file}\")\n",
    "\n",
    "    # Find the corresponding timestamp CSV\n",
    "    base_name = os.path.splitext(video_file)[0].split('_')[-1]\n",
    "    timestamp_file = next((path for name, path in timestamp_files.items() if base_name in name), None)\n",
    "\n",
    "    if not timestamp_file:\n",
    "        print(f\"No timestamp file found for video: {video_file}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load frame timestamps from the timestamp CSV\n",
    "    try:\n",
    "        frame_timestamps = pd.read_csv(timestamp_file)\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        if 'frame_number' not in frame_timestamps.columns or 'timestamp' not in frame_timestamps.columns:\n",
    "            print(f\"Invalid timestamp file format for {video_file}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Validate timestamp column\n",
    "        if not np.issubdtype(frame_timestamps['timestamp'].dtype, np.number):\n",
    "            print(f\"Timestamp column in {video_file} is not numeric. Converting.\")\n",
    "            frame_timestamps['timestamp'] = pd.to_numeric(frame_timestamps['timestamp'], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading timestamp file for {video_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Open the corresponding commands CSV\n",
    "    timestamp = \"_\".join(os.path.splitext(video_file)[0].split('_')[-2:])\n",
    "    commands_file = os.path.join(commands_dir, f\"commands_{timestamp}.csv\")\n",
    "\n",
    "    if not os.path.exists(commands_file):\n",
    "        print(f\"No commands file found for video: {video_file}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load commands\n",
    "    try:\n",
    "        commands = pd.read_csv(commands_file)\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        if 'timestamp' not in commands.columns or 'linear_velocity' not in commands.columns or 'angular_velocity' not in commands.columns:\n",
    "            print(f\"Invalid commands file format for {video_file}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Validate timestamp and velocity columns\n",
    "        commands['timestamp'] = pd.to_numeric(commands['timestamp'], errors='coerce')\n",
    "        commands['linear_velocity'] = pd.to_numeric(commands['linear_velocity'], errors='coerce')\n",
    "        commands['angular_velocity'] = pd.to_numeric(commands['angular_velocity'], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading commands file for {video_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video: {video_file}\")\n",
    "        continue\n",
    "\n",
    "    # Process frames\n",
    "    frames = []\n",
    "    frame_data = []\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        # Preprocess the frame\n",
    "        frame_resized = cv2.resize(frame, img_size, interpolation=cv2.INTER_AREA) / 255.0\n",
    "\n",
    "        # Get the exact timestamp for this frame\n",
    "        frame_timestamp = frame_timestamps.loc[frame_timestamps['frame_number'] == frame_count, 'timestamp']\n",
    "\n",
    "        if not frame_timestamp.empty:\n",
    "            frames.append(frame_resized)\n",
    "            frame_data.append({\n",
    "                'timestamp': frame_timestamp.values[0],\n",
    "                'frame_index': frame_count\n",
    "            })\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {len(frames)} frames from video: {video_file}\")\n",
    "\n",
    "    # Convert frame data to DataFrame\n",
    "    frame_df = pd.DataFrame(frame_data)\n",
    "\n",
    "    # Perform time-based join with commands\n",
    "    aligned_data = pd.merge_asof(\n",
    "        frame_df,\n",
    "        commands.sort_values('timestamp'),\n",
    "        on='timestamp',\n",
    "        direction='backward',\n",
    "        tolerance=max_sync_gap  # Max time difference allowed\n",
    "    )\n",
    "\n",
    "    # Handle cases where no recent command was found\n",
    "    if aligned_data['linear_velocity'].isna().any():\n",
    "        print(f\"Warning: Some frames in {video_file} could not be synchronized with commands.\")\n",
    "\n",
    "        # Optional: forward fill missing velocities\n",
    "        aligned_data['linear_velocity'].ffill()\n",
    "        aligned_data['angular_velocity'].ffill()\n",
    "    # Remove any remaining rows with NaN velocities\n",
    "    aligned_data.dropna(subset=['linear_velocity', 'angular_velocity'], inplace=True)\n",
    "\n",
    "    # Create final data structure\n",
    "    synchronized_frames = [frames[int(idx)] for idx in aligned_data['frame_index']]\n",
    "    synchronized_commands = aligned_data[['timestamp', 'linear_velocity', 'angular_velocity']].values\n",
    "\n",
    "    # Store results for this video\n",
    "    data[video_file] = {\n",
    "        \"frames\": np.array(synchronized_frames),\n",
    "        \"commands\": synchronized_commands,\n",
    "    }\n",
    "\n",
    "    print(f\"Synchronized {len(synchronized_frames)} frames with commands for {video_file}\")\n",
    "\n",
    "print(\"Finished processing all videos.\")\n",
    "\n",
    "# Check if the data dictionary contains any processed videos\n",
    "if not data:\n",
    "    print(\"No videos were successfully processed. Please check your data and paths.\")\n",
    "else:\n",
    "    # Example: Access frames and commands for a specific video\n",
    "    example_video = next(iter(data.keys()))  # Get the first successfully processed video\n",
    "    frames = data[example_video][\"frames\"]\n",
    "    commands = data[example_video][\"commands\"]\n",
    "    print(f\"Frames shape: {frames.shape}\")\n",
    "    print(f\"Commands shape: {commands.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vV1fWqQwWu-w"
   },
   "source": [
    "## Verify video data is correctly encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QofZeVsBBYJh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrieve the aligned data for the example video\n",
    "aligned_timestamps = data[example_video][\"commands\"]  # Commands and timestamps\n",
    "frames = data[example_video][\"frames\"]\n",
    "\n",
    "# Visualize the first 200 frames with additional information\n",
    "for i in range(100,102):  # Ensure we don't exceed the number of frames\n",
    "    # Retrieve timestamp and command for the current frame\n",
    "    frame_timestamp = aligned_timestamps[i][0] if i < len(aligned_timestamps) else None\n",
    "    linear_velocity = aligned_timestamps[i][1] if i < len(aligned_timestamps) else None\n",
    "    angular_velocity = aligned_timestamps[i][2] if i < len(aligned_timestamps) else None\n",
    "\n",
    "    # Display the frame\n",
    "    plt.imshow(frames[i])\n",
    "    title_text = f\"Frame {i} | Timestamp: {frame_timestamp:.3f} | Linear Vel: {linear_velocity:.3f} | Angular Vel: {angular_velocity:.3f}\"\n",
    "    plt.title(title_text)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M8EPrUvXEsA"
   },
   "source": [
    "#Divide data for model training, verification and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5fW_wDs6VcGU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Define the directory to save preprocessed data\n",
    "output_dir = r'C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data'\n",
    "\n",
    "# Randomly shuffle video keys\n",
    "video_keys = list(data.keys())\n",
    "random.shuffle(video_keys)\n",
    "\n",
    "# Define split ratios\n",
    "train_split = int(0.7 * len(video_keys))\n",
    "val_split = int(0.9 * len(video_keys))\n",
    "\n",
    "# Split data\n",
    "train_videos = video_keys[:train_split]\n",
    "val_videos = video_keys[train_split:val_split]\n",
    "test_videos = video_keys[val_split:]\n",
    "\n",
    "# Save split datasets\n",
    "split_dir = os.path.join(output_dir, \"splits\")\n",
    "os.makedirs(split_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kYp2-xg-rUJT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train split with 4 videos to C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits\\train_split.pkl\n",
      "Saved val split with 2 videos to C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits\\val_split.pkl\n",
      "Saved test split with 1 videos to C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits\\test_split.pkl\n"
     ]
    }
   ],
   "source": [
    "#make pickle\n",
    "for split_name, split_videos in [(\"train\", train_videos), (\"val\", val_videos), (\"test\", test_videos)]:\n",
    "    split_file = os.path.join(split_dir, f\"{split_name}_split.pkl\")\n",
    "    with open(split_file, \"wb\") as f:\n",
    "        split_data = {video: data[video] for video in split_videos}\n",
    "        pickle.dump(split_data, f)\n",
    "    print(f\"Saved {split_name} split with {len(split_videos)} videos to {split_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr_w9_GG7gLD"
   },
   "source": [
    "##**start running code cells here if you have no new data to add for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1733074228707,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "AXlhKmpD6yjH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# split_dir = \"/content/drive/My Drive/BASC, third year/ENPH 353/Competition Project/Preprocessed Data/splits\"\n",
    "split_dir = r'C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data'\n",
    "\n",
    "train_path = os.path.join(split_dir, \"train_split.pkl\")\n",
    "val_path = os.path.join(split_dir, \"val_split.pkl\")\n",
    "test_path = os.path.join(split_dir, \"test_split.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_Bv-PvQXJm5"
   },
   "source": [
    "## VERIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2000,
     "status": "ok",
     "timestamp": 1733074104148,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "GY-K4OXWWNFI",
    "outputId": "c3234e6d-40b2-4adf-d502-17d2ba46df60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits\\train_split.pkl\n",
      "File exists: C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits\\val_split.pkl\n",
      "File exists: C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits\\test_split.pkl\n"
     ]
    }
   ],
   "source": [
    "# Check if split files exist\n",
    "# split_dir = \"/content/drive/My Drive/BASC, third year/ENPH 353/Competition Project/Preprocessed Data/splits\"\n",
    "split_dir = r'C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits'\n",
    "split_files = [\"train_split.pkl\", \"val_split.pkl\", \"test_split.pkl\"]\n",
    "\n",
    "for split_file in split_files:\n",
    "    split_path = os.path.join(split_dir, split_file)\n",
    "    if os.path.exists(split_path):\n",
    "        print(f\"File exists: {split_path}\")\n",
    "    else:\n",
    "        print(f\"Missing file: {split_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16922,
     "status": "ok",
     "timestamp": 1733051651649,
     "user": {
      "displayName": "Anton Shoham",
      "userId": "18304469040041226183"
     },
     "user_tz": 480
    },
    "id": "o8cRlAB5WUw-",
    "outputId": "1d8a660a-1b6a-4027-e8ab-5fa8ecc89d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split.pkl: 4 videos\n",
      "  Video: video_output_20241130_003337.mp4\n",
      "    Frames shape: (2005, 112, 112, 3)\n",
      "    Commands shape: (2005, 3)\n",
      "  Video: video_output_20241130_003756.mp4\n",
      "    Frames shape: (2245, 112, 112, 3)\n",
      "    Commands shape: (2245, 3)\n",
      "val_split.pkl: 2 videos\n",
      "  Video: video_output_20241130_004101.mp4\n",
      "    Frames shape: (1560, 112, 112, 3)\n",
      "    Commands shape: (1560, 3)\n",
      "  Video: video_output_20241130_004447.mp4\n",
      "    Frames shape: (1847, 112, 112, 3)\n",
      "    Commands shape: (1847, 3)\n",
      "test_split.pkl: 1 videos\n",
      "  Video: video_output_20241130_002438.mp4\n",
      "    Frames shape: (2107, 112, 112, 3)\n",
      "    Commands shape: (2107, 3)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load and inspect splits\n",
    "for split_file in split_files:\n",
    "    split_path = os.path.join(split_dir, split_file)\n",
    "    with open(split_path, \"rb\") as f:\n",
    "        split_data = pickle.load(f)\n",
    "\n",
    "    print(f\"{split_file}: {len(split_data)} videos\")\n",
    "    for video_key, video_data in list(split_data.items())[:2]:  # Display the first 2 entries\n",
    "        print(f\"  Video: {video_key}\")\n",
    "        print(f\"    Frames shape: {video_data['frames'].shape}\")\n",
    "        print(f\"    Commands shape: {video_data['commands'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10713,
     "status": "ok",
     "timestamp": 1733051662359,
     "user": {
      "displayName": "Anton Shoham",
      "userId": "18304469040041226183"
     },
     "user_tz": 480
    },
    "id": "ID80qyvoWeVr",
    "outputId": "4b6b7882-0d6f-41d4-8d21-e383a04f6bab"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load train split\n",
    "train_split_path = os.path.join(split_dir, \"train_split.pkl\")\n",
    "with open(train_split_path, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# Select a sample video\n",
    "sample_video = next(iter(train_data.keys()))\n",
    "sample_data = train_data[sample_video]\n",
    "\n",
    "# Inspect sample frames and commands\n",
    "frames = sample_data[\"frames\"]\n",
    "commands = sample_data[\"commands\"]\n",
    "\n",
    "print(f\"Sample video: {sample_video}\")\n",
    "print(f\"Frames shape: {frames.shape}\")\n",
    "print(f\"Commands shape: {commands.shape}\")\n",
    "\n",
    "# Visualize a few frames with commands\n",
    "for i in range(min(2, len(frames))):\n",
    "    plt.imshow(frames[i])\n",
    "    command_text = f\"Linear Vel: {commands[i, 1]:.2f}, Angular Vel: {commands[i, 2]:.2f}\"\n",
    "    plt.title(f\"Frame {i} | {command_text}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ur8lCWVZY3b"
   },
   "source": [
    "#INSTANTIATE NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AY5BZP4V3lOq"
   },
   "source": [
    "##ensure right version of tensorflow is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3691,
     "status": "ok",
     "timestamp": 1733074238618,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "Rv_oC8z53s30",
    "outputId": "4f825813-3de0-438b-d9f2-ec39a68c18e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # Should output 2.13.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD5HMabzgR2t"
   },
   "source": [
    "##Load data for model use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1733074241885,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "2g8opOddmtvA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def data_generator(data, batch_size=32):\n",
    "    keys = list(data.keys())\n",
    "    num_samples = sum(len(video_data[\"frames\"]) for video_data in data.values())\n",
    "    while True:\n",
    "        X, y = [], []\n",
    "        for video_key in keys:\n",
    "            video_data = data[video_key]\n",
    "            frames = video_data[\"frames\"]\n",
    "            commands = video_data[\"commands\"]\n",
    "            for i in range(len(frames)):\n",
    "                X.append(frames[i])\n",
    "                y.append(commands[i, 1:])  # Skip timestamp\n",
    "                if len(X) == batch_size:\n",
    "                    yield np.array(X), np.array(y)\n",
    "                    X, y = [], []\n",
    "        if X:  # Yield remaining samples in the last batch\n",
    "            yield np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 57515,
     "status": "ok",
     "timestamp": 1733074316615,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "R_D0TMXKZd5Y"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load preprocessed splits\n",
    "#split_dir = \"/content/drive/My Drive/BASC, third year/ENPH 353/Competition Project/Preprocessed Data/splits\"\n",
    "split_dir = r'C:\\Users\\anton\\Documents\\Competition Project\\Preprocessed Data\\splits'\n",
    "\n",
    "\n",
    "train_path = os.path.join(split_dir, \"train_split.pkl\")\n",
    "val_path = os.path.join(split_dir, \"val_split.pkl\")\n",
    "\n",
    "with open(train_path, \"rb\") as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "with open(val_path, \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "# Create generators for training and validation data\n",
    "train_generator = data_generator(train_data, batch_size=32)\n",
    "val_generator = data_generator(val_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1733074325264,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "V0ZC_D2Qnekt",
    "outputId": "568d3983-9ca4-4d2d-963b-f7dc245e1430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: (32, 112, 112, 3), (32, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test train generator\n",
    "X_batch, y_batch = next(train_generator)\n",
    "print(f\"Batch shape: {X_batch.shape}, {y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEP-8OzUoI-A"
   },
   "source": [
    "##define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1307,
     "status": "ok",
     "timestamp": 1733074329288,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "evLKWOojoKW3",
    "outputId": "17569399-52f8-4475-b0a8-ba0f83fea998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 110, 110, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 55, 55, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 53, 53, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 26, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2359424   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2461058 (9.39 MB)\n",
      "Trainable params: 2461058 (9.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(112, 112, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='linear')  # Output: linear_velocity, angular_velocity\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhnk-4D6nNj3"
   },
   "source": [
    "##train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2068639,
     "status": "ok",
     "timestamp": 1733077861537,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "3KCU_uB6nMHV",
    "outputId": "d7c2dada-ee70-4317-ba68-db4d39bb7035"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3504893209.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    filepath='C:\\Users\\anton\\Documents\\Competition Project\\Trained Models\\imitation_model_3.h5',\u001b[0m\n\u001b[1;37m                                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# Calculate steps per epoch\n",
    "train_steps = sum(len(video_data[\"frames\"]) for video_data in train_data.values()) // 32\n",
    "val_steps = sum(len(video_data[\"frames\"]) for video_data in val_data.values()) // 32\n",
    "\n",
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=r'C:\\Users\\anton\\Documents\\Competition Project\\Trained Models\\imitation_model_3.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_format='h5'  # Explicitly set save format to HDF5\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "# Visualize training progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCl_UbiysLqt"
   },
   "source": [
    "##save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1733078089828,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "YzrjTvpNsLQF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\anton\\Documents\\Competition Project\\Trained Models\\imitation_model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2671,
     "status": "ok",
     "timestamp": 1733078076990,
     "user": {
      "displayName": "Tracy S",
      "userId": "04049828360841644911"
     },
     "user_tz": 480
    },
    "id": "0sqX1V0w0MyW",
    "outputId": "baf1aad1-1c04-4058-dda5-fadaaf45963a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"/content/drive/My Drive/Competition Project/Trained Models/best_model.h5\"\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cIC-9fw51gn1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
